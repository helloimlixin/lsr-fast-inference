# @package _global_.training
output_dir: ./outputs/kronecker_calibration
num_train_epochs: 1
per_device_train_batch_size: 2
per_device_eval_batch_size: 2
gradient_accumulation_steps: 4
eval_strategy: steps
eval_steps: 100
logging_steps: 10
learning_rate: 5.0e-05
weight_decay: 0.001
metric_for_best_model: perplexity
greater_is_better: false
fp16: true
gradient_checkpointing: true
deepspeed: ds_config.json
dataset_name: wikitext
dataset_config: wikitext-103-raw-v1
max_seq_length: 2048