# @package _global_.training

# Default training configuration
output_dir: "./outputs/kronecker_lora_finetune"
num_train_epochs: 3
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
eval_strategy: "steps"
eval_steps: 100
save_strategy: "steps"
save_steps: 100
logging_steps: 10
learning_rate: 5e-6
weight_decay: 0.01
load_best_model_at_end: true
metric_for_best_model: "accuracy"
greater_is_better: true
early_stopping_patience: 3
metric_name: "glue"
metric_subset: "sst2"
